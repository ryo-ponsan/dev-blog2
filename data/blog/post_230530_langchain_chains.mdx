---
title: LangChain chains
date: '2023-05-30'
tags: ['LangChain', 'chatGPT', 'OpenAI', 'API']
draft: false
summary: 'LangChain'
authors: ['gypsyR']
---

- [ツール：LangChain がネイティブでサポートするさまざまなタイプのツールをカバーします。また、自分自身のツールを追加する方法もカバーします。](https://python.langchain.com/en/latest/modules/agents/tools.html)

## 目次

- [チェーン作成の sample](#1)
- [非同期チェーンの実行](#2)
- [カスタムチェーンの実装](#3)
- [LangChainHub から chains の流用](#4)
- [LLMChain の仕様で LLM オブジェクトにアクセス](#5)

<a id="1"></a>

# [チェーン作成の sample](https://python.langchain.com/en/latest/modules/chains/getting_started.html)

LangChain では、チェーンを使用して複数のコンポーネントを組み合わせ、一つの連続したアプリケーションを作成することができます。例えば、ユーザーの入力を取り、それを PromptTemplate でフォーマットし、その結果を LLM（Language Model）に渡すというチェーンを作成することができます。より複雑なチェーンは、複数のチェーンを組み合わせるか、チェーンと他のコンポーネントを組み合わせることで作成できます。

以下に、LangChain でチェーンを作成し、それを使用する方法をステップバイステップで説明します。

## 1. LLMChain の使用

LLMChain は、プロンプトテンプレートを取り、それをユーザーの入力でフォーマットし、LLM からの応答を返すシンプルなチェーンです。

```python
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
from langchain.chains import LLMChain

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)

chain = LLMChain(llm=llm, prompt=prompt)

# Run the chain only specifying the input variable.
print(chain.run("colorful socks"))
```

## 2. チェーンの呼び出し方法

Chain から継承したすべてのクラスは、チェーンのロジックを実行するいくつかの方法を提供します。最も直接的な方法は、**call**を使用することです。

```python
chat = ChatOpenAI(temperature=0)
prompt_template = "Tell me a {adjective} joke"
llm_chain = LLMChain(
    llm=chat,
    prompt=PromptTemplate.from_template(prompt_template)
)

llm_chain(inputs={"adjective":"corny"})
```

## 3. チェーンにメモリを追加

Chain は BaseMemory オブジェクトをメモリ引数として受け取ることができ、これにより Chain オブジェクトは複数の呼び出しにわたってデータを保持することができます。つまり、Chain を状態を持つオブジェクトにすることができます。

```python
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

conversation = ConversationChain(
    llm=chat,
    memory=ConversationBufferMemory()
)

conversation.run("Answer briefly. What are the first 3 colors of a rainbow?")
conversation.run("And the next 4?")
```

## 4. SequentialChain を使用してチェーンを組み合わせる

SequentialChain は、事前に定義された順序でリンクを

（続き）

実行するチェーンです。具体的には、SimpleSequentialChain を使用します。これは最もシンプルなタイプのシーケンシャルチェーンで、各ステップには一つの入力/出力があり、一つのステップの出力が次のステップの入力となります。

```python
from langchain.chains import SimpleSequentialChain

second_prompt = PromptTemplate(
    input_variables=["company_name"],
    template="Write a catchphrase for the following company: {company_name}",
)
chain_two = LLMChain(llm=llm, prompt=second_prompt)

# Combine the two LLMChains
overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)

# Run the chain specifying only the input variable for the first chain.
catchphrase = overall_chain.run("colorful socks")
print(catchphrase)
```

## 5. Chain クラスを使用してカスタムチェーンを作成

LangChain は多くのチェーンを提供していますが、特定のユースケースに対応するためにカスタムチェーンを作成することもあります。カスタムチェーンを作成するためには、以下の手順を実行します。

1. Chain クラスをサブクラス化します。
2. input_keys と output_keys プロパティを記入します。
3. チェーンの実行方法を示す\_call メソッドを追加します。

```python
from langchain.chains import LLMChain
from langchain.chains.base import Chain
from typing import Dict, List

class ConcatenateChain(Chain):
    chain_1: LLMChain
    chain_2: LLMChain

    @property
    def input_keys(self) -> List[str]:
        # Union of the input keys of the two chains.
        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))
        return list(all_input_vars)

    @property
    def output_keys(self) -> List[str]:
        return ['concat_output']

    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:
        output_1 = self.chain_1.run(inputs)
        output_2 = self.chain_2.run(inputs)
        return {'concat_output': output_1 + output_2}

concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)
concat_output = concat_chain.run("colorful socks")
print(f"Concatenated output:\n{concat_output}")
```

以上が、LangChain でチェーンを作成し、それを使用する方法のステップバイステップの説明です。これらのステップを参考に、自分のニーズに合わせてチェーンを作成し、使用することができます。

<a id="2"></a>

# [非同期チェーンの実行](https://python.langchain.com/en/latest/modules/chains/generic/async_chain.html)

LangChain では、非同期（async）サポートを利用してチェーンを実行することができます。これは、Python の asyncio ライブラリを活用しています。現在、LLMChain（arun, apredict, acall メソッドを通じて）、LLMMathChain（arun と acall メソッドを通じて）、ChatVectorDBChain、および QA チェーンで非同期メソッドがサポートされています。他のチェーンに対する非同期サポートはロードマップ上にあります。

以下に、LangChain で非同期チェーンを使用する方法をステップバイステップで説明します。

## 1. 必要なモジュールのインポート

まず、必要なモジュールをインポートします。

```python
import asyncio
import time

from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
```

## 2. 非同期チェーンの生成

次に、非同期チェーンを生成します。

```python
async def async_generate(chain):
    resp = await chain.arun(product="toothpaste")
    print(resp)
```

## 3. 非同期チェーンの並行実行

非同期チェーンを並行して実行します。

```python
async def generate_concurrently():
    llm = OpenAI(temperature=0.9)
    prompt = PromptTemplate(
        input_variables=["product"],
        template="What is a good name for a company that makes {product}?",
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    tasks = [async_generate(chain) for _ in range(5)]
    await asyncio.gather(*tasks)
```

## 4. 非同期チェーンの実行

最後に、非同期チェーンを実行します。

```python
s = time.perf_counter()
# If running this outside of Jupyter, use asyncio.run(generate_concurrently())
await generate_concurrently()
elapsed = time.perf_counter() - s
print('\\033[1m' + f"Concurrent executed in {elapsed:0.2f} seconds." + '\\033[0m')
```

以上が、LangChain で非同期チェーンを使用する方法のステップバイステップの説明です。これらのステップを参考に、自分のニーズに合わせて非同期チェーンを作成し、使用することができます。

<a id="3"></a>

# [カスタムチェーンの実行](https://python.langchain.com/en/latest/modules/chains/generic/custom_chain.html)

独自のカスタムチェーンを実装するには、Chain をサブクラス化し、以下のメソッドを実装します

```python
from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import Extra

from langchain.base_language import BaseLanguageModel
from langchain.callbacks.manager import (
    AsyncCallbackManagerForChainRun,
    CallbackManagerForChainRun,
)
from langchain.chains.base import Chain
from langchain.prompts.base import BasePromptTemplate


class MyCustomChain(Chain):
    """
    An example of a custom chain.
    """

    prompt: BasePromptTemplate
    """Prompt object to use."""
    llm: BaseLanguageModel
    output_key: str = "text"  #: :meta private:

    class Config:
        """Configuration for this pydantic object."""

        extra = Extra.forbid
        arbitrary_types_allowed = True

    @property
    def input_keys(self) -> List[str]:
        """Will be whatever keys the prompt expects.

        :meta private:
        """
        return self.prompt.input_variables

    @property
    def output_keys(self) -> List[str]:
        """Will always return text key.

        :meta private:
        """
        return [self.output_key]

    def _call(
        self,
        inputs: Dict[str, Any],
        run_manager: Optional[CallbackManagerForChainRun] = None,
    ) -> Dict[str, str]:
        # Your custom chain logic goes here
        # This is just an example that mimics LLMChain
        prompt_value = self.prompt.format_prompt(**inputs)

        # Whenever you call a language model, or another chain, you should pass
        # a callback manager to it. This allows the inner run to be tracked by
        # any callbacks that are registered on the outer run.
        # You can always obtain a callback manager for this by calling
        # `run_manager.get_child()` as shown below.
        response = self.llm.generate_prompt(
            [prompt_value],
            callbacks=run_manager.get_child() if run_manager else None
        )

        # If you want to log something about this run, you can do so by calling
        # methods on the `run_manager`, as shown below. This will trigger any
        # callbacks that are registered for that event.
        if run_manager:
            run_manager.on_text("Log something about this run")

        return {self.output_key: response.generations[0][0].text}

    async def _acall(
        self,
        inputs: Dict[str, Any],
        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,
    ) -> Dict[str, str]:
        # Your custom chain logic goes here
        # This is just an example that mimics LLMChain
        prompt_value = self.prompt.format_prompt(**inputs)

        # Whenever you call a language model, or another chain, you should pass
        # a callback manager to it. This allows the inner run to be tracked by
        # any callbacks that are registered on the outer run.
        # You can always obtain a callback manager for this by calling
        # `run_manager.get_child()` as shown below.
        response = await self.llm.agenerate_prompt(
            [prompt_value],
            callbacks=run_manager.get_child() if run_manager else None
        )

        # If you want to log something about this run, you can do so by calling
        # methods on the `run_manager`, as shown below. This will trigger any
        # callbacks that are registered for that event.
        if run_manager:
            await run_manager.on_text("Log something about this run")

        return {self.output_key: response.generations[0][0].text}

    @property
    def _chain_type(self) -> str:
        return "my_custom_chain"
```

```python
from langchain.callbacks.stdout import StdOutCallbackHandler
from langchain.chat_models.openai import ChatOpenAI
from langchain.prompts.prompt import PromptTemplate


chain = MyCustomChain(
    prompt=PromptTemplate.from_template('tell us a joke about {topic}'),
    llm=ChatOpenAI()
)

chain.run({'topic': 'callbacks'}, callbacks=[StdOutCallbackHandler()])
```

```
> Entering new MyCustomChain chain...
Log something about this run
> Finished chain.
```

```
'Why did the callback function feel lonely? Because it was always waiting for someone to call it back!'
```

<a id="4"></a>

# [LangChainHub からチェーンの流用](https://python.langchain.com/en/latest/modules/chains/generic/from_hub.html)

LangChain では、LangChainHub からチェーンをロードすることができます。この機能を利用することで、事前に定義されたチェーンを簡単に使用することができます。

以下に、LangChainHub からチェーンをロードする方法をステップバイステップで説明します。

## 1. 必要なモジュールのインポート

まず、必要なモジュールをインポートします。

```python
from langchain.chains import load_chain
```

## 2. LangChainHub からチェーンのロード

次に、LangChainHub からチェーンをロードします。

```python
chain = load_chain("lc://chains/llm-math/chain.json")
```

## 3. チェーンの実行

最後に、ロードしたチェーンを実行します。

```python
chain.run("whats 2 raised to .12")
```

なお、チェーンは時々、シリアライズされたチェーンと一緒には保存されていない追加の引数を必要とすることがあります。例えば、ベクトルデータベース上で質問応答を行うチェーンは、ベクトルデータベースを必要とします。

```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain import OpenAI, VectorDBQA
from langchain.document_loaders import TextLoader

loader = TextLoader('../../state_of_the_union.txt')
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(texts, embeddings)

chain = load_chain("lc://chains/vector-db-qa/stuff/chain.json", vectorstore=vectorstore)

query = "What did the president say about Ketanji Brown Jackson"
chain.run(query)
```

以上が、LangChainHub からチェーンをロードする方法のステップバイステップの説明です。これらのステップを参考に、LangChainHub からチェーンをロードし、使用することができます。

<a id="5"></a>

# [LLMChain の仕様で LLM オブジェクトにアクセス](https://python.langchain.com/en/latest/modules/chains/generic/llm_chain.html)

LangChain では、LLMChain を使用して LLM（Language Model）オブジェクトを問い合わせることができます。LLMChain は、入力キー値（および利用可能な場合はメモリキー値）を使用してプロンプトテンプレートをフォーマットし、フォーマットされた文字列を LLM に渡し、LLM の出力を返します。

以下に、LangChain で LLMChain を使用する方法をステップバイステップで説明します。

## 1. LLMChain の使用

LLMChain は、プロンプトテンプレートを取り、それをユーザーの入力でフォーマットし、LLM からの応答を返すシンプルなチェーンです。

```python
from langchain import PromptTemplate, OpenAI, LLMChain

prompt_template = "What is a good name for a company that makes {product}?"

llm = OpenAI(temperature=0)
llm_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(prompt_template)
)
llm_chain("colorful socks")
```

## 2. LLMChain の追加的な実行方法

LLMChain は、Chain オブジェクトが共有する**call**と run メソッドの他にも、チェーンのロジックを呼び出すいくつかの方法を提供します。

- apply メソッドを使用すると、チェーンを入力リストに対して実行することができます。
- generate メソッドは apply に似ていますが、LLMResult を返します。LLMResult は、トークンの使用状況や終了理由などの有用な生成を含むことがあります。
- predict メソッドは run メソッドに似ていますが、入力キーは Python の辞書ではなくキーワード引数として指定されます。

## 3. 出力の解析

デフォルトでは、LLMChain は基礎となるプロンプトオブジェクトに出力パーサーがあっても出力を解析しません。LLM の出力に出力パーサーを適用したい場合は、predict の代わりに predict_and_parse を、apply の代わりに apply_and_parse を使用します。

## 4. 文字列からの初期化

文字列テンプレートから直接 LLMChain を構築することもできます。

```python
template = "Tell me a {adjective} joke about {subject}."
llm_chain = LLMChain.from_string(llm=llm, template=template)

llm_chain.predict(adjective="sad", subject="ducks")
```

以上が、LangChain で LLMChain を使用する方法のステップバイステップの説明です。これらのステップを参考に、自分のニーズに合わせて LLMChain を作成し、使用することができます。

<a id="6"></a>

# [Router Chains で動的にチェーン選択](https://python.langchain.com/en/latest/modules/chains/generic/router.html)

LangChain では、RouterChain パラダイムを使用して、与えられた入力に対して次に使用するチェーンを動的に選択するチェーンを作成することができます。Router chains は 2 つのコンポーネントから構成されています。

1. RouterChain 自体（次に呼び出すチェーンを選択する責任があります）
2. destination_chains：router chain がルーティングできるチェーン

以下に、LangChain で RouterChain を使用する方法をステップバイステップで説明します。

## 1. 必要なモジュールのインポート

まず、必要なモジュールをインポートします。

```python
from langchain.chains.router import MultiPromptChain
from langchain.llms import OpenAI
from langchain.chains import ConversationChain
from langchain.chains.llm import LLMChain
from langchain.prompts import PromptTemplate
```

## 2. プロンプトテンプレートの作成

次に、プロンプトテンプレートを作成します。

```python
physics_template = "You are a very smart physics professor. \
You are great at answering questions about physics in a concise and easy to understand manner. \
When you don't know the answer to a question you admit that you don't know.\n\nHere is a question:\n{input}"

math_template = "You are a very good mathematician. You are great at answering math questions. \
You are so good because you are able to break down hard problems into their component parts, \
answer the component parts, and then put them together to answer the broader question.\n\nHere is a question:\n{input}"

prompt_infos = [
    {
        "name": "physics",
        "description": "Good for answering questions about physics",
        "prompt_template": physics_template
    },
    {
        "name": "math",
        "description": "Good for answering math questions",
        "prompt_template": math_template
    }
]
```

## 3. チェーンの作成

次に、プロンプトテンプレートを使用してチェーンを作成します。

```python
destination_chains = {}
for p_info in prompt_infos:
    name = p_info["name"]
    prompt_template = p_info["prompt_template"]
    prompt = PromptTemplate(template=prompt_template, input_variables=["input"])
    chain = LLMChain(llm=llm, prompt=prompt)
    destination_chains[name] = chain
default_chain = ConversationChain(llm=llm, output_key="text")
```

## 4. LLMRouterChain の使用

このチェーンは、LLM を使用してルーティングを行います。

```python
from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE

destinations = [f"{p['name']}: {p['description']}" for p in prompt_infos]
destinations_str = "\n".join(destinations)
router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(
    destinations=destinations_str
)
router_prompt = PromptTemplate(
    template=router_template,
    input_variables=["input"],
    output_parser=

（続き）

RouterOutputParser(),
)
router_chain = LLMRouterChain.from_llm(llm, router_prompt)

chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True)
```

## 5. チェーンの実行

最後に、作成したチェーンを実行します。

```python
print(chain.run("What is black body radiation?"))
print(chain.run("What is the first prime number greater than 40 such that one plus the prime number is divisible by 3"))
print(chain.run("What is the name of the type of cloud that rains?"))
```

## 6. EmbeddingRouterChain の使用

EmbeddingRouterChain は、埋め込みと類似性を使用してチェーン間をルーティングします。

```python
from langchain.chains.router.embedding_router import EmbeddingRouterChain
from langchain.embeddings import CohereEmbeddings
from langchain.vectorstores import Chroma

names_and_descriptions = [
    ("physics", ["for questions about physics"]),
    ("math", ["for questions about math"]),
]

router_chain = EmbeddingRouterChain.from_names_and_descriptions(
    names_and_descriptions, Chroma, CohereEmbeddings(), routing_keys=["input"]
)

chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True)
```

以上が、LangChain で RouterChain を使用する方法のステップバイステップの説明です。これらのステップを参考に、自分のニーズに合わせて RouterChain を作成し、使用することができます。
